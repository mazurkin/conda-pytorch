{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca0ff2d4-909b-4e2c-a479-a84f02f7fca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn, torch.utils.data as data, torchvision as tv, torch.nn.functional as F\n",
    "import lightning as L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b86d362-0aad-45d9-8044-391502bede91",
   "metadata": {},
   "source": [
    "https://github.com/Lightning-AI/pytorch-lightning?tab=readme-ov-file#hello-simple-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b99376a-8ca5-4896-856a-99465feaf88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# Step 1: Define a LightningModule\n",
    "# --------------------------------\n",
    "# A LightningModule (nn.Module subclass) defines a full *system*\n",
    "# (ie: an LLM, diffusion model, autoencoder, or simple image classifier).\n",
    "\n",
    "\n",
    "class LitAutoEncoder(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(nn.Linear(28 * 28, 128), nn.ReLU(), nn.Linear(128, 3))\n",
    "        self.decoder = nn.Sequential(nn.Linear(3, 128), nn.ReLU(), nn.Linear(128, 28 * 28))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # in lightning, forward defines the prediction/inference actions\n",
    "        embedding = self.encoder(x)\n",
    "        return embedding\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop. It is independent of forward\n",
    "        x, _ = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        loss = F.mse_loss(x_hat, x)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ca14e50-a6a7-483b-9b7e-af19c622ae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------\n",
    "# Step 2: Define data\n",
    "# -------------------\n",
    "dataset = tv.datasets.MNIST(\"./data\", download=True, transform=tv.transforms.ToTensor())\n",
    "train, val = data.random_split(dataset, [55000, 5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5380caea-09f6-4b44-8efa-53a8f33d3e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0maccelerator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAccelerator\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstrategy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStrategy\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdevices\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnum_nodes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprecision\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLiteral\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'transformer-engine'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'transformer-engine-float16'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'16-true'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'16-mixed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bf16-true'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bf16-mixed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'32-true'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'64-true'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'64'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'32'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'16'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bf16'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlogger\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloggers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloggers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogger\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfast_dev_run\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_epochs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmin_epochs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_steps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmin_steps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_time\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlimit_train_batches\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlimit_val_batches\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlimit_test_batches\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlimit_predict_batches\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moverfit_batches\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mval_check_interval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcheck_val_every_n_epoch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnum_sanity_val_steps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlog_every_n_steps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0menable_checkpointing\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0menable_progress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0menable_model_summary\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0maccumulate_grad_batches\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgradient_clip_val\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgradient_clip_algorithm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdeterministic\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'warn'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbenchmark\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minference_mode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0muse_distributed_sampler\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprofiler\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofilers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProfiler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdetect_anomaly\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbarebones\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mplugins\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPrecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfabric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_environment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClusterEnvironment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfabric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckpointIO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_sync\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerSync\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPrecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfabric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_environment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClusterEnvironment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfabric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckpointIO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_sync\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerSync\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msync_batchnorm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreload_dataloaders_every_n_epochs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdefault_root_dir\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmodel_registry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m      <no docstring>\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "Customize every aspect of training via flags.\n",
       "\n",
       "Args:\n",
       "    accelerator: Supports passing different accelerator types (\"cpu\", \"gpu\", \"tpu\", \"hpu\", \"mps\", \"auto\")\n",
       "        as well as custom accelerator instances.\n",
       "\n",
       "    strategy: Supports different training strategies with aliases as well custom strategies.\n",
       "        Default: ``\"auto\"``.\n",
       "\n",
       "    devices: The devices to use. Can be set to a positive number (int or str), a sequence of device indices\n",
       "        (list or str), the value ``-1`` to indicate all available devices should be used, or ``\"auto\"`` for\n",
       "        automatic selection based on the chosen accelerator. Default: ``\"auto\"``.\n",
       "\n",
       "    num_nodes: Number of GPU nodes for distributed training.\n",
       "        Default: ``1``.\n",
       "\n",
       "    precision: Double precision (64, '64' or '64-true'), full precision (32, '32' or '32-true'),\n",
       "        16bit mixed precision (16, '16', '16-mixed') or bfloat16 mixed precision ('bf16', 'bf16-mixed').\n",
       "        Can be used on CPU, GPU, TPUs, or HPUs.\n",
       "        Default: ``'32-true'``.\n",
       "\n",
       "    logger: Logger (or iterable collection of loggers) for experiment tracking. A ``True`` value uses\n",
       "        the default ``TensorBoardLogger`` if it is installed, otherwise ``CSVLogger``.\n",
       "        ``False`` will disable logging. If multiple loggers are provided, local files\n",
       "        (checkpoints, profiler traces, etc.) are saved in the ``log_dir`` of the first logger.\n",
       "        Default: ``True``.\n",
       "\n",
       "    callbacks: Add a callback or list of callbacks.\n",
       "        Default: ``None``.\n",
       "\n",
       "    fast_dev_run: Runs n if set to ``n`` (int) else 1 if set to ``True`` batch(es)\n",
       "        of train, val and test to find any bugs (ie: a sort of unit test).\n",
       "        Default: ``False``.\n",
       "\n",
       "    max_epochs: Stop training once this number of epochs is reached. Disabled by default (None).\n",
       "        If both max_epochs and max_steps are not specified, defaults to ``max_epochs = 1000``.\n",
       "        To enable infinite training, set ``max_epochs = -1``.\n",
       "\n",
       "    min_epochs: Force training for at least these many epochs. Disabled by default (None).\n",
       "\n",
       "    max_steps: Stop training after this number of steps. Disabled by default (-1). If ``max_steps = -1``\n",
       "        and ``max_epochs = None``, will default to ``max_epochs = 1000``. To enable infinite training, set\n",
       "        ``max_epochs`` to ``-1``.\n",
       "\n",
       "    min_steps: Force training for at least these number of steps. Disabled by default (``None``).\n",
       "\n",
       "    max_time: Stop training after this amount of time has passed. Disabled by default (``None``).\n",
       "        The time duration can be specified in the format DD:HH:MM:SS (days, hours, minutes seconds), as a\n",
       "        :class:`datetime.timedelta`, or a dictionary with keys that will be passed to\n",
       "        :class:`datetime.timedelta`.\n",
       "\n",
       "    limit_train_batches: How much of training dataset to check (float = fraction, int = num_batches).\n",
       "        Default: ``1.0``.\n",
       "\n",
       "    limit_val_batches: How much of validation dataset to check (float = fraction, int = num_batches).\n",
       "        Default: ``1.0``.\n",
       "\n",
       "    limit_test_batches: How much of test dataset to check (float = fraction, int = num_batches).\n",
       "        Default: ``1.0``.\n",
       "\n",
       "    limit_predict_batches: How much of prediction dataset to check (float = fraction, int = num_batches).\n",
       "        Default: ``1.0``.\n",
       "\n",
       "    overfit_batches: Overfit a fraction of training/validation data (float) or a set number of batches (int).\n",
       "        Default: ``0.0``.\n",
       "\n",
       "    val_check_interval: How often to check the validation set. Pass a ``float`` in the range [0.0, 1.0] to check\n",
       "        after a fraction of the training epoch. Pass an ``int`` to check after a fixed number of training\n",
       "        batches. An ``int`` value can only be higher than the number of training batches when\n",
       "        ``check_val_every_n_epoch=None``, which validates after every ``N`` training batches\n",
       "        across epochs or during iteration-based training.\n",
       "        Default: ``1.0``.\n",
       "\n",
       "    check_val_every_n_epoch: Perform a validation loop after every `N` training epochs. If ``None``,\n",
       "        validation will be done solely based on the number of training batches, requiring ``val_check_interval``\n",
       "        to be an integer value.\n",
       "        Default: ``1``.\n",
       "\n",
       "    num_sanity_val_steps: Sanity check runs n validation batches before starting the training routine.\n",
       "        Set it to `-1` to run all batches in all validation dataloaders.\n",
       "        Default: ``2``.\n",
       "\n",
       "    log_every_n_steps: How often to log within steps.\n",
       "        Default: ``50``.\n",
       "\n",
       "    enable_checkpointing: If ``True``, enable checkpointing.\n",
       "        It will configure a default ModelCheckpoint callback if there is no user-defined ModelCheckpoint in\n",
       "        :paramref:`~lightning.pytorch.trainer.trainer.Trainer.callbacks`.\n",
       "        Default: ``True``.\n",
       "\n",
       "    enable_progress_bar: Whether to enable to progress bar by default.\n",
       "        Default: ``True``.\n",
       "\n",
       "    enable_model_summary: Whether to enable model summarization by default.\n",
       "        Default: ``True``.\n",
       "\n",
       "    accumulate_grad_batches: Accumulates gradients over k batches before stepping the optimizer.\n",
       "        Default: 1.\n",
       "\n",
       "    gradient_clip_val: The value at which to clip gradients. Passing ``gradient_clip_val=None`` disables\n",
       "        gradient clipping. If using Automatic Mixed Precision (AMP), the gradients will be unscaled before.\n",
       "        Default: ``None``.\n",
       "\n",
       "    gradient_clip_algorithm: The gradient clipping algorithm to use. Pass ``gradient_clip_algorithm=\"value\"``\n",
       "        to clip by value, and ``gradient_clip_algorithm=\"norm\"`` to clip by norm. By default it will\n",
       "        be set to ``\"norm\"``.\n",
       "\n",
       "    deterministic: If ``True``, sets whether PyTorch operations must use deterministic algorithms.\n",
       "        Set to ``\"warn\"`` to use deterministic algorithms whenever possible, throwing warnings on operations\n",
       "        that don't support deterministic mode. If not set, defaults to ``False``. Default: ``None``.\n",
       "\n",
       "    benchmark: The value (``True`` or ``False``) to set ``torch.backends.cudnn.benchmark`` to.\n",
       "        The value for ``torch.backends.cudnn.benchmark`` set in the current session will be used\n",
       "        (``False`` if not manually set). If :paramref:`~lightning.pytorch.trainer.trainer.Trainer.deterministic`\n",
       "        is set to ``True``, this will default to ``False``. Override to manually set a different value.\n",
       "        Default: ``None``.\n",
       "\n",
       "    inference_mode: Whether to use :func:`torch.inference_mode` or :func:`torch.no_grad` during\n",
       "        evaluation (``validate``/``test``/``predict``).\n",
       "\n",
       "    use_distributed_sampler: Whether to wrap the DataLoader's sampler with\n",
       "        :class:`torch.utils.data.DistributedSampler`. If not specified this is toggled automatically for\n",
       "        strategies that require it. By default, it will add ``shuffle=True`` for the train sampler and\n",
       "        ``shuffle=False`` for validation/test/predict samplers. If you want to disable this logic, you can pass\n",
       "        ``False`` and add your own distributed sampler in the dataloader hooks. If ``True`` and a distributed\n",
       "        sampler was already added, Lightning will not replace the existing one. For iterable-style datasets,\n",
       "        we don't do this automatically.\n",
       "\n",
       "    profiler: To profile individual steps during training and assist in identifying bottlenecks.\n",
       "        Default: ``None``.\n",
       "\n",
       "    detect_anomaly: Enable anomaly detection for the autograd engine.\n",
       "        Default: ``False``.\n",
       "\n",
       "    barebones: Whether to run in \"barebones mode\", where all features that may impact raw speed are\n",
       "        disabled. This is meant for analyzing the Trainer overhead and is discouraged during regular training\n",
       "        runs. The following features are deactivated:\n",
       "        :paramref:`~lightning.pytorch.trainer.trainer.Trainer.enable_checkpointing`,\n",
       "        :paramref:`~lightning.pytorch.trainer.trainer.Trainer.logger`,\n",
       "        :paramref:`~lightning.pytorch.trainer.trainer.Trainer.enable_progress_bar`,\n",
       "        :paramref:`~lightning.pytorch.trainer.trainer.Trainer.log_every_n_steps`,\n",
       "        :paramref:`~lightning.pytorch.trainer.trainer.Trainer.enable_model_summary`,\n",
       "        :paramref:`~lightning.pytorch.trainer.trainer.Trainer.num_sanity_val_steps`,\n",
       "        :paramref:`~lightning.pytorch.trainer.trainer.Trainer.fast_dev_run`,\n",
       "        :paramref:`~lightning.pytorch.trainer.trainer.Trainer.detect_anomaly`,\n",
       "        :paramref:`~lightning.pytorch.trainer.trainer.Trainer.profiler`,\n",
       "        :meth:`~lightning.pytorch.core.LightningModule.log`,\n",
       "        :meth:`~lightning.pytorch.core.LightningModule.log_dict`.\n",
       "    plugins: Plugins allow modification of core behavior like ddp and amp, and enable custom lightning plugins.\n",
       "        Default: ``None``.\n",
       "\n",
       "    sync_batchnorm: Synchronize batch norm layers between process groups/whole world.\n",
       "        Default: ``False``.\n",
       "\n",
       "    reload_dataloaders_every_n_epochs: Set to a positive integer to reload dataloaders every n epochs.\n",
       "        Default: ``0``.\n",
       "\n",
       "    default_root_dir: Default path for logs and weights when no logger/ckpt_callback passed.\n",
       "        Default: ``os.getcwd()``.\n",
       "        Can be remote file paths such as `s3://mybucket/path` or 'hdfs://path/'\n",
       "\n",
       "    model_registry: The name of the model being uploaded to Model hub.\n",
       "\n",
       "Raises:\n",
       "    TypeError:\n",
       "        If ``gradient_clip_val`` is not an int or float.\n",
       "\n",
       "    MisconfigurationException:\n",
       "        If ``gradient_clip_algorithm`` is invalid.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/.conda/envs/pytorch/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "L.Trainer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45152a67-d2be-4011-838d-8f9fba7ac548",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type       | Params | Mode \n",
      "-----------------------------------------------\n",
      "0 | encoder | Sequential | 100 K  | train\n",
      "1 | decoder | Sequential | 101 K  | train\n",
      "-----------------------------------------------\n",
      "202 K     Trainable params\n",
      "0         Non-trainable params\n",
      "202 K     Total params\n",
      "0.810     Total estimated model params size (MB)\n",
      "8         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "source": [
    "# -------------------\n",
    "# Step 3: Train\n",
    "# -------------------\n",
    "autoencoder = LitAutoEncoder()\n",
    "trainer = L.Trainer(limit_train_batches=1000, max_epochs=3, log_every_n_steps=100, enable_progress_bar=False)\n",
    "trainer.fit(autoencoder, data.DataLoader(train), data.DataLoader(val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
