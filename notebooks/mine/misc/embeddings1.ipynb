{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "570d938a-2b00-410a-aec4-754c7404f9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca6ae73-aceb-4e05-8c5e-83853b443c4b",
   "metadata": {},
   "source": [
    "https://medium.com/biased-algorithms/pytorch-embedding-layer-for-categorical-data-096af5757353"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfadf006-d51c-43af-ac17-dd6891f92430",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenreClassifier(nn.Module):\n",
    "    def __init__(self, num_genres, embedding_dim, output_dim):\n",
    "        super(GenreClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_genres, embedding_dim)\n",
    "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        out = self.fc(embedded)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af85a3af-5cfe-4f75-b47a-be283c2311f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data: 5 genres (integer-encoded)\n",
    "genre_data = torch.LongTensor([0, 1, 2, 3, 4])\n",
    "\n",
    "# Sample target classes (binary classification: 0 or 1 for each genre)\n",
    "target_data = torch.FloatTensor([0, 1, 0, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12847c26-8348-40c6-bdd9-03df1e3a85c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/1000], Loss: 0.7672\n",
      "Epoch [20/1000], Loss: 0.7468\n",
      "Epoch [30/1000], Loss: 0.7273\n",
      "Epoch [40/1000], Loss: 0.7084\n",
      "Epoch [50/1000], Loss: 0.6900\n",
      "Epoch [60/1000], Loss: 0.6719\n",
      "Epoch [70/1000], Loss: 0.6540\n",
      "Epoch [80/1000], Loss: 0.6361\n",
      "Epoch [90/1000], Loss: 0.6181\n",
      "Epoch [100/1000], Loss: 0.6000\n",
      "Epoch [110/1000], Loss: 0.5816\n",
      "Epoch [120/1000], Loss: 0.5631\n",
      "Epoch [130/1000], Loss: 0.5443\n",
      "Epoch [140/1000], Loss: 0.5254\n",
      "Epoch [150/1000], Loss: 0.5063\n",
      "Epoch [160/1000], Loss: 0.4872\n",
      "Epoch [170/1000], Loss: 0.4680\n",
      "Epoch [180/1000], Loss: 0.4489\n",
      "Epoch [190/1000], Loss: 0.4299\n",
      "Epoch [200/1000], Loss: 0.4110\n",
      "Epoch [210/1000], Loss: 0.3925\n",
      "Epoch [220/1000], Loss: 0.3742\n",
      "Epoch [230/1000], Loss: 0.3563\n",
      "Epoch [240/1000], Loss: 0.3388\n",
      "Epoch [250/1000], Loss: 0.3218\n",
      "Epoch [260/1000], Loss: 0.3053\n",
      "Epoch [270/1000], Loss: 0.2893\n",
      "Epoch [280/1000], Loss: 0.2739\n",
      "Epoch [290/1000], Loss: 0.2591\n",
      "Epoch [300/1000], Loss: 0.2449\n",
      "Epoch [310/1000], Loss: 0.2313\n",
      "Epoch [320/1000], Loss: 0.2183\n",
      "Epoch [330/1000], Loss: 0.2059\n",
      "Epoch [340/1000], Loss: 0.1942\n",
      "Epoch [350/1000], Loss: 0.1831\n",
      "Epoch [360/1000], Loss: 0.1726\n",
      "Epoch [370/1000], Loss: 0.1626\n",
      "Epoch [380/1000], Loss: 0.1533\n",
      "Epoch [390/1000], Loss: 0.1444\n",
      "Epoch [400/1000], Loss: 0.1361\n",
      "Epoch [410/1000], Loss: 0.1284\n",
      "Epoch [420/1000], Loss: 0.1211\n",
      "Epoch [430/1000], Loss: 0.1142\n",
      "Epoch [440/1000], Loss: 0.1078\n",
      "Epoch [450/1000], Loss: 0.1018\n",
      "Epoch [460/1000], Loss: 0.0961\n",
      "Epoch [470/1000], Loss: 0.0909\n",
      "Epoch [480/1000], Loss: 0.0860\n",
      "Epoch [490/1000], Loss: 0.0813\n",
      "Epoch [500/1000], Loss: 0.0770\n",
      "Epoch [510/1000], Loss: 0.0730\n",
      "Epoch [520/1000], Loss: 0.0692\n",
      "Epoch [530/1000], Loss: 0.0657\n",
      "Epoch [540/1000], Loss: 0.0624\n",
      "Epoch [550/1000], Loss: 0.0593\n",
      "Epoch [560/1000], Loss: 0.0564\n",
      "Epoch [570/1000], Loss: 0.0537\n",
      "Epoch [580/1000], Loss: 0.0511\n",
      "Epoch [590/1000], Loss: 0.0487\n",
      "Epoch [600/1000], Loss: 0.0464\n",
      "Epoch [610/1000], Loss: 0.0443\n",
      "Epoch [620/1000], Loss: 0.0423\n",
      "Epoch [630/1000], Loss: 0.0405\n",
      "Epoch [640/1000], Loss: 0.0387\n",
      "Epoch [650/1000], Loss: 0.0370\n",
      "Epoch [660/1000], Loss: 0.0355\n",
      "Epoch [670/1000], Loss: 0.0340\n",
      "Epoch [680/1000], Loss: 0.0326\n",
      "Epoch [690/1000], Loss: 0.0313\n",
      "Epoch [700/1000], Loss: 0.0300\n",
      "Epoch [710/1000], Loss: 0.0289\n",
      "Epoch [720/1000], Loss: 0.0277\n",
      "Epoch [730/1000], Loss: 0.0267\n",
      "Epoch [740/1000], Loss: 0.0257\n",
      "Epoch [750/1000], Loss: 0.0247\n",
      "Epoch [760/1000], Loss: 0.0238\n",
      "Epoch [770/1000], Loss: 0.0230\n",
      "Epoch [780/1000], Loss: 0.0221\n",
      "Epoch [790/1000], Loss: 0.0214\n",
      "Epoch [800/1000], Loss: 0.0206\n",
      "Epoch [810/1000], Loss: 0.0199\n",
      "Epoch [820/1000], Loss: 0.0193\n",
      "Epoch [830/1000], Loss: 0.0186\n",
      "Epoch [840/1000], Loss: 0.0180\n",
      "Epoch [850/1000], Loss: 0.0174\n",
      "Epoch [860/1000], Loss: 0.0169\n",
      "Epoch [870/1000], Loss: 0.0163\n",
      "Epoch [880/1000], Loss: 0.0158\n",
      "Epoch [890/1000], Loss: 0.0153\n",
      "Epoch [900/1000], Loss: 0.0149\n",
      "Epoch [910/1000], Loss: 0.0144\n",
      "Epoch [920/1000], Loss: 0.0140\n",
      "Epoch [930/1000], Loss: 0.0136\n",
      "Epoch [940/1000], Loss: 0.0132\n",
      "Epoch [950/1000], Loss: 0.0128\n",
      "Epoch [960/1000], Loss: 0.0125\n",
      "Epoch [970/1000], Loss: 0.0121\n",
      "Epoch [980/1000], Loss: 0.0118\n",
      "Epoch [990/1000], Loss: 0.0115\n",
      "Epoch [1000/1000], Loss: 0.0112\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "embedding_dim = 10\n",
    "num_genres = 5\n",
    "output_dim = 1\n",
    "\n",
    "# Initialize the model\n",
    "model = GenreClassifier(num_genres, embedding_dim, output_dim)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    \n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(genre_data)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = criterion(output.squeeze(), target_data)\n",
    "    \n",
    "    # Backward pass and optimize\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfffe17c-5603-4707-aaca-156e5f8bbe0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Classes: tensor([[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Predict the class for each genre\n",
    "    predictions = torch.sigmoid(model(genre_data))\n",
    "    predicted_classes = (predictions > 0.5).float()\n",
    "    \n",
    "    print(f'Predicted Classes: {predicted_classes}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
