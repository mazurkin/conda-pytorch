{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45759adf-1abf-4c7e-9e8c-1336460dcf96",
   "metadata": {},
   "source": [
    "https://github.com/omarsar/pytorch_notebooks/blob/master/pytorch_hello_world.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cbd8d4-d541-4974-8f94-1c7ece1c0f20",
   "metadata": {},
   "source": [
    "https://medium.com/dair-ai/a-first-shot-at-deep-learning-with-pytorch-4a8252d30c75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7ff6f10-f983-421a-bdb3-be52d4d0f0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0+cu118\n"
     ]
    }
   ],
   "source": [
    "## The usual imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "## print out the pytorch version used\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a7ae0ff-c9c3-44f3-a906-c2f79b4c00d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## our data in tensor form\n",
    "x = torch.tensor([[-1.0],  [0.0], [1.0], [2.0], [3.0], [4.0]], dtype=torch.float)\n",
    "y = torch.tensor([[-3.0], [-1.0], [1.0], [3.0], [5.0], [7.0]], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e101b667-c4b7-4654-b951-4bfc795a8ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print size of the input tensor\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4c99460-fb6e-49f0-8432-17f4685b59c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Neural network with 1 hidden layer\n",
    "layer1 = nn.Linear(1, 1, bias=False)\n",
    "model = nn.Sequential(layer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82878ed3-c2b4-45e2-b688-2e68b6313e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "## optimizer algorithm\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4dcb7a2-98e0-418d-8f6b-067298936145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 21.9104\n",
      "Epoch: 1 | Loss: 17.7268\n",
      "Epoch: 2 | Loss: 14.3632\n",
      "Epoch: 3 | Loss: 11.6588\n",
      "Epoch: 4 | Loss: 9.4845\n",
      "Epoch: 5 | Loss: 7.7362\n",
      "Epoch: 6 | Loss: 6.3307\n",
      "Epoch: 7 | Loss: 5.2006\n",
      "Epoch: 8 | Loss: 4.2920\n",
      "Epoch: 9 | Loss: 3.5614\n",
      "Epoch: 10 | Loss: 2.9741\n",
      "Epoch: 11 | Loss: 2.5018\n",
      "Epoch: 12 | Loss: 2.1221\n",
      "Epoch: 13 | Loss: 1.8169\n",
      "Epoch: 14 | Loss: 1.5714\n",
      "Epoch: 15 | Loss: 1.3741\n",
      "Epoch: 16 | Loss: 1.2154\n",
      "Epoch: 17 | Loss: 1.0878\n",
      "Epoch: 18 | Loss: 0.9853\n",
      "Epoch: 19 | Loss: 0.9028\n",
      "Epoch: 20 | Loss: 0.8365\n",
      "Epoch: 21 | Loss: 0.7832\n",
      "Epoch: 22 | Loss: 0.7403\n",
      "Epoch: 23 | Loss: 0.7059\n",
      "Epoch: 24 | Loss: 0.6782\n",
      "Epoch: 25 | Loss: 0.6559\n",
      "Epoch: 26 | Loss: 0.6380\n",
      "Epoch: 27 | Loss: 0.6236\n",
      "Epoch: 28 | Loss: 0.6120\n",
      "Epoch: 29 | Loss: 0.6027\n",
      "Epoch: 30 | Loss: 0.5952\n",
      "Epoch: 31 | Loss: 0.5892\n",
      "Epoch: 32 | Loss: 0.5844\n",
      "Epoch: 33 | Loss: 0.5805\n",
      "Epoch: 34 | Loss: 0.5773\n",
      "Epoch: 35 | Loss: 0.5748\n",
      "Epoch: 36 | Loss: 0.5728\n",
      "Epoch: 37 | Loss: 0.5712\n",
      "Epoch: 38 | Loss: 0.5699\n",
      "Epoch: 39 | Loss: 0.5688\n",
      "Epoch: 40 | Loss: 0.5680\n",
      "Epoch: 41 | Loss: 0.5673\n",
      "Epoch: 42 | Loss: 0.5668\n",
      "Epoch: 43 | Loss: 0.5663\n",
      "Epoch: 44 | Loss: 0.5660\n",
      "Epoch: 45 | Loss: 0.5657\n",
      "Epoch: 46 | Loss: 0.5655\n",
      "Epoch: 47 | Loss: 0.5653\n",
      "Epoch: 48 | Loss: 0.5651\n",
      "Epoch: 49 | Loss: 0.5650\n",
      "Epoch: 50 | Loss: 0.5649\n",
      "Epoch: 51 | Loss: 0.5648\n",
      "Epoch: 52 | Loss: 0.5648\n",
      "Epoch: 53 | Loss: 0.5647\n",
      "Epoch: 54 | Loss: 0.5647\n",
      "Epoch: 55 | Loss: 0.5646\n",
      "Epoch: 56 | Loss: 0.5646\n",
      "Epoch: 57 | Loss: 0.5646\n",
      "Epoch: 58 | Loss: 0.5646\n",
      "Epoch: 59 | Loss: 0.5646\n",
      "Epoch: 60 | Loss: 0.5646\n",
      "Epoch: 61 | Loss: 0.5646\n",
      "Epoch: 62 | Loss: 0.5645\n",
      "Epoch: 63 | Loss: 0.5645\n",
      "Epoch: 64 | Loss: 0.5645\n",
      "Epoch: 65 | Loss: 0.5645\n",
      "Epoch: 66 | Loss: 0.5645\n",
      "Epoch: 67 | Loss: 0.5645\n",
      "Epoch: 68 | Loss: 0.5645\n",
      "Epoch: 69 | Loss: 0.5645\n",
      "Epoch: 70 | Loss: 0.5645\n",
      "Epoch: 71 | Loss: 0.5645\n",
      "Epoch: 72 | Loss: 0.5645\n",
      "Epoch: 73 | Loss: 0.5645\n",
      "Epoch: 74 | Loss: 0.5645\n",
      "Epoch: 75 | Loss: 0.5645\n",
      "Epoch: 76 | Loss: 0.5645\n",
      "Epoch: 77 | Loss: 0.5645\n",
      "Epoch: 78 | Loss: 0.5645\n",
      "Epoch: 79 | Loss: 0.5645\n",
      "Epoch: 80 | Loss: 0.5645\n",
      "Epoch: 81 | Loss: 0.5645\n",
      "Epoch: 82 | Loss: 0.5645\n",
      "Epoch: 83 | Loss: 0.5645\n",
      "Epoch: 84 | Loss: 0.5645\n",
      "Epoch: 85 | Loss: 0.5645\n",
      "Epoch: 86 | Loss: 0.5645\n",
      "Epoch: 87 | Loss: 0.5645\n",
      "Epoch: 88 | Loss: 0.5645\n",
      "Epoch: 89 | Loss: 0.5645\n",
      "Epoch: 90 | Loss: 0.5645\n",
      "Epoch: 91 | Loss: 0.5645\n",
      "Epoch: 92 | Loss: 0.5645\n",
      "Epoch: 93 | Loss: 0.5645\n",
      "Epoch: 94 | Loss: 0.5645\n",
      "Epoch: 95 | Loss: 0.5645\n",
      "Epoch: 96 | Loss: 0.5645\n",
      "Epoch: 97 | Loss: 0.5645\n",
      "Epoch: 98 | Loss: 0.5645\n",
      "Epoch: 99 | Loss: 0.5645\n",
      "Epoch: 100 | Loss: 0.5645\n",
      "Epoch: 101 | Loss: 0.5645\n",
      "Epoch: 102 | Loss: 0.5645\n",
      "Epoch: 103 | Loss: 0.5645\n",
      "Epoch: 104 | Loss: 0.5645\n",
      "Epoch: 105 | Loss: 0.5645\n",
      "Epoch: 106 | Loss: 0.5645\n",
      "Epoch: 107 | Loss: 0.5645\n",
      "Epoch: 108 | Loss: 0.5645\n",
      "Epoch: 109 | Loss: 0.5645\n",
      "Epoch: 110 | Loss: 0.5645\n",
      "Epoch: 111 | Loss: 0.5645\n",
      "Epoch: 112 | Loss: 0.5645\n",
      "Epoch: 113 | Loss: 0.5645\n",
      "Epoch: 114 | Loss: 0.5645\n",
      "Epoch: 115 | Loss: 0.5645\n",
      "Epoch: 116 | Loss: 0.5645\n",
      "Epoch: 117 | Loss: 0.5645\n",
      "Epoch: 118 | Loss: 0.5645\n",
      "Epoch: 119 | Loss: 0.5645\n",
      "Epoch: 120 | Loss: 0.5645\n",
      "Epoch: 121 | Loss: 0.5645\n",
      "Epoch: 122 | Loss: 0.5645\n",
      "Epoch: 123 | Loss: 0.5645\n",
      "Epoch: 124 | Loss: 0.5645\n",
      "Epoch: 125 | Loss: 0.5645\n",
      "Epoch: 126 | Loss: 0.5645\n",
      "Epoch: 127 | Loss: 0.5645\n",
      "Epoch: 128 | Loss: 0.5645\n",
      "Epoch: 129 | Loss: 0.5645\n",
      "Epoch: 130 | Loss: 0.5645\n",
      "Epoch: 131 | Loss: 0.5645\n",
      "Epoch: 132 | Loss: 0.5645\n",
      "Epoch: 133 | Loss: 0.5645\n",
      "Epoch: 134 | Loss: 0.5645\n",
      "Epoch: 135 | Loss: 0.5645\n",
      "Epoch: 136 | Loss: 0.5645\n",
      "Epoch: 137 | Loss: 0.5645\n",
      "Epoch: 138 | Loss: 0.5645\n",
      "Epoch: 139 | Loss: 0.5645\n",
      "Epoch: 140 | Loss: 0.5645\n",
      "Epoch: 141 | Loss: 0.5645\n",
      "Epoch: 142 | Loss: 0.5645\n",
      "Epoch: 143 | Loss: 0.5645\n",
      "Epoch: 144 | Loss: 0.5645\n",
      "Epoch: 145 | Loss: 0.5645\n",
      "Epoch: 146 | Loss: 0.5645\n",
      "Epoch: 147 | Loss: 0.5645\n",
      "Epoch: 148 | Loss: 0.5645\n",
      "Epoch: 149 | Loss: 0.5645\n"
     ]
    }
   ],
   "source": [
    "## training\n",
    "epoch = 150\n",
    "for i in range(150):\n",
    "    model = model.train()\n",
    "    train_running_loss = 0.0\n",
    "\n",
    "    ## forward\n",
    "    output = model(x)\n",
    "    loss = criterion(output, y)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    ## backward + update model params \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_running_loss += loss.detach().item()\n",
    "\n",
    "    model.eval()\n",
    "    print('Epoch: %d | Loss: %.4f' %(i, train_running_loss) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d1543ab-79b8-44a8-9cbe-bf159bc11fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.096769332885742\n"
     ]
    }
   ],
   "source": [
    "## test the model\n",
    "sample = torch.tensor([10.0], dtype=torch.float)\n",
    "predicted = model(sample)\n",
    "print(predicted.detach().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644ac09d-ebb3-44ed-9e54-0c0cc6841a18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cee1121-6928-4b0b-a8b9-e7024a6b3802",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
